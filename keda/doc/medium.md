<!-- ![KEDA](https://github.com/robertasolimandonofreo/medium-projects/blob/main/keda/doc/keda.png) -->

# Autoscaling Inteligente no Kubernetes com KEDA: Al√©m do CPU e Mem√≥ria

Se voc√™ trabalha com Kubernetes, provavelmente j√° se viu em uma situa√ß√£o inc√¥moda: seu aplicativo est√° processando filas, respondendo a webhooks ou lidando com picos de tr√°fego, e o Horizontal Pod Autoscaler (HPA) nativo fica preso olhando s√≥ para CPU e mem√≥ria. Resultado? Pods que n√£o escalam quando deveriam ou que escalam no tempo errado.

Eu passei por isso mais vezes do que gostaria de admitir. At√© descobrir que o KEDA resolve esse problema de um jeito bem elegante (e open source).

> **C√≥digo completo deste artigo:** https://github.com/robertasolimandonofreo/medium-projects/tree/main/keda

Todos os exemplos pr√°ticos que vou mostrar est√£o nesse reposit√≥rio. Voc√™ pode clonar e testar localmente!

## O Problema Real

O HPA padr√£o do Kubernetes √© b√°sico demais para cen√°rios do mundo real. Imagine que voc√™ tem:

- Uma aplica√ß√£o que consome mensagens de uma fila RabbitMQ
- Um worker que processa jobs de um Redis
- Um servi√ßo que depende de lat√™ncia de uma API externa
- Um batch job que deveria escalar baseado no tamanho de um bucket S3

Em todos esses casos, CPU e mem√≥ria n√£o dizem muita coisa. A sua fila pode estar explodindo enquanto o CPU dos seus pods est√° em 10%. Voc√™ precisa escalar porque h√° trabalho na fila, n√£o porque h√° calor na m√°quina.

A√≠ entra o KEDA.

## O que √© KEDA?

KEDA √© basicamente um autoscaler que entende eventos. Em vez de s√≥ olhar para m√©tricas tradicionais, ele se conecta a diversas fontes e diz: "ei, tem 5 mil mensagens nessa fila, precisa de mais pods!".

A beleza √© que ele suporta dezenas de scalers: RabbitMQ, Kafka, Redis, AWS SQS, Google Pub/Sub, Azure Service Bus, webhooks customizados‚Ä¶ a lista √© grande.

## Preparando o Ambiente

### Pr√©-requisitos

Antes de come√ßar, voc√™ precisar√° de:

- K3s instalado
- Helm 3 instalado
- kubectl configurado

### Instalar K3s

Se voc√™ ainda n√£o tem K3s instalado, execute:

```bash
curl -sfL https://get.k3s.io | sh -
sudo systemctl status k3s
```

Copiar o kubeconfig:

```bash
sudo cp /etc/rancher/k3s/k3s.yaml ~/.kube/config
sudo chown $(id -u):$(id -g) ~/.kube/config
```

### Descobrir o IP do Cluster

Este √© um detalhe importante! Voc√™ vai precisar do IP do seu n√≥ para acessar os servi√ßos expostos via NodePort.

```bash
export NODE_IP=$(kubectl get nodes -o wide | awk 'NR==2 {print $6}')
echo "NODE_IP: $NODE_IP"
```

Guarde este IP, voc√™ vai usar para acessar RabbitMQ UI, APIs e outros servi√ßos nos pr√≥ximos passos!

### Instalar Helm

```bash
curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash
```

## Instalando o KEDA

Agora, vamos colocar KEDA no cluster:

```bash
helm repo add kedacore https://kedacore.github.io/charts
helm repo update
helm install keda kedacore/keda --namespace keda --create-namespace
kubectl get pods -n keda
```

Pronto. Agora voc√™ tem dois novos recursos dispon√≠veis: `ScaledObject` e `ScaledJob`. Vamos usar o primeiro para aplica√ß√µes normais.

## Exemplo 1: Escalando por Fila RabbitMQ (Com Exemplo Real)

Vamos come√ßar com um caso cl√°ssico: voc√™ tem workers processando mensagens de um RabbitMQ. Quanto mais mensagens na fila, mais workers voc√™ quer.

### Passo 1: Instalar o RabbitMQ Cluster Operator

```bash
kubectl apply -f "https://github.com/rabbitmq/cluster-operator/releases/latest/download/cluster-operator.yml"
kubectl get pods -n rabbitmq-system
```

### Passo 2: Criar o Cluster RabbitMQ

```yaml
apiVersion: rabbitmq.com/v1beta1
kind: RabbitmqCluster
metadata:
  name: rabbitmq
  namespace: rabbitmq
spec:
  replicas: 1
  resources:
    requests:
      cpu: 100m
      memory: 128Mi
    limits:
      cpu: 500m
      memory: 512Mi
  rabbitmq:
    additionalConfig: |
      log.console.level = info
      channel_max = 1700
      default_user = rabbitmq
      default_pass = rabbitmq
      default_user_tags.administrator = true
      prometheus.tcp.port = 15692
    additionalPlugins:
      - rabbitmq_prometheus
  persistence:
    storageClassName: local-path
    storage: 1Gi
  service:
    type: NodePort
```

Criar namespace e aplicar:

```bash
kubectl create ns rabbitmq
kubectl apply -f cluster.yaml
```

### Passo 3: Criar a Fila de Teste

```bash
curl -i -u rabbitmq:rabbitmq -H "content-type: application/json" \
-XPUT http://${NODE_IP}:32062/api/queues/%2f/keda-queue \
-d '{"auto_delete":false,"durable":true}'
```

### Passo 4: Publicar Mensagens de Teste

```bash
for i in {1..20}; do
  curl -i -u rabbitmq:rabbitmq \
    -H "content-type: application/json" \
    -XPOST http://${NODE_IP}:32062/api/exchanges/%2f/amq.default/publish \
    -d '{"properties":{},"routing_key":"keda-queue","payload":"msg","payload_encoding":"string"}'
done
```

### Passo 5: Deployment do Consumer

Agora, o deployment do seu worker:

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: rabbit-consumer
spec:
  replicas: 1
  selector:
    matchLabels:
      app: rabbit-consumer
  template:
    metadata:
      labels:
        app: rabbit-consumer
    spec:
      containers:
      - name: consumer
        image: busybox
        command: ["sh", "-c", "echo 'Consumidor ativo...'; sleep 3600"]
```

### Passo 6: Configurar o ScaledObject

Agora, o ScaledObject que faz a m√°gica:

```yaml
apiVersion: keda.sh/v1alpha1
kind: ScaledObject
metadata:
  name: rabbit-consumer-scaler
  namespace: default
spec:
  scaleTargetRef:
    name: rabbit-consumer
  pollingInterval: 10
  cooldownPeriod: 30
  minReplicaCount: 1
  maxReplicaCount: 5
  triggers:
  - type: rabbitmq
    metadata:
      protocol: amqp
      queueName: keda-queue
      mode: QueueLength
      value: "5"
      host: "amqp://rabbitmq:rabbitmq@rabbitmq.rabbitmq.svc.cluster.local:5672/"
```

Traduzindo: o KEDA vai verificar a fila `keda-queue` do RabbitMQ a cada 10 segundos. Se tiver mais de 5 mensagens por pod, ele adiciona mais pods. Se tiver menos, reduz.

Ent√£o se a fila tem 20 mensagens e voc√™ j√° tem 1 pod, ele calcula: (20 / 5) = 4 pods. Pronto, vai criar mais 3.

**Monitorar o scaling:**

```bash
kubectl get deployment rabbit-consumer --watch
kubectl describe scaledobject rabbit-consumer-scaler
```

## Exemplo 2: Redis - Contando Itens em uma Lista (Com Implementa√ß√£o Real)

Agora vamos para algo um pouco diferente. Voc√™ tem uma aplica√ß√£o que processa itens de uma lista Redis, e quer escalar baseado no comprimento dessa lista.

### Passo 1: Instalar Redis

```bash
helm repo add bitnami https://charts.bitnami.com/bitnami
helm repo update
helm install redis bitnami/redis \
  --namespace redis --create-namespace \
  --set auth.enabled=false \
  --set metrics.enabled=true \
  --set metrics.serviceMonitor.enabled=false
```

Verificar:

```bash
kubectl get pods -n redis
```

### Passo 2: Adicionar Itens na Lista Redis

```bash
kubectl exec -it -n redis redis-master-0 -- redis-cli LPUSH keda-list "msg1"
kubectl exec -it -n redis redis-master-0 -- redis-cli LPUSH keda-list "msg2"
kubectl exec -it -n redis redis-master-0 -- redis-cli LPUSH keda-list "msg3"
kubectl exec -it -n redis redis-master-0 -- redis-cli LPUSH keda-list "msg4"
kubectl exec -it -n redis redis-master-0 -- redis-cli LPUSH keda-list "msg5"
kubectl exec -it -n redis redis-master-0 -- redis-cli LPUSH keda-list "msg6"
```

### Passo 3: Deployment do Consumer Redis

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-consumer
  namespace: default
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis-consumer
  template:
    metadata:
      labels:
        app: redis-consumer
    spec:
      containers:
      - name: redis-consumer
        image: busybox
        command: ["sh", "-c", "echo 'Consumidor Redis ativo'; sleep 3600"]
```

### Passo 4: ScaledObject para Redis

```yaml
apiVersion: keda.sh/v1alpha1
kind: ScaledObject
metadata:
  name: redis-consumer-scaler
  namespace: default
spec:
  scaleTargetRef:
    name: redis-consumer
  pollingInterval: 10
  cooldownPeriod: 30
  minReplicaCount: 1
  maxReplicaCount: 5
  triggers:
  - type: redis
    metadata:
      address: "redis-master.redis.svc.cluster.local:6379"
      listName: "keda-list"
      listLength: "5"
```

Simples assim. O KEDA vai contar quantos itens tem na lista e dividir por 5. Se tiver 30 itens, escalar√° para 6 pods (30 / 5 = 6).

**Monitorar:**

```bash
kubectl get deployment redis-consumer --watch
```
Todos os pods criados pelo KEDA:

![PODS](https://github.com/robertasolimandonofreo/medium-projects/blob/main/keda/doc/pod.png)

## Exemplo 3: Escalando por M√©trica Customizada (Prometheus)

Agora vem a parte mais poderosa: voc√™ pode escalar baseado em qualquer m√©trica que voc√™ consiga exportar para o Prometheus.

Imagine que voc√™ quer escalar uma aplica√ß√£o de video processing baseado no tempo m√©dio de processamento. Se a lat√™ncia est√° acima de 5 segundos, voc√™ quer mais workers.

```yaml
apiVersion: keda.sh/v1alpha1
kind: ScaledObject
metadata:
  name: custom-metric-scaler
spec:
  scaleTargetRef:
    name: video-processor
  minReplicaCount: 2
  maxReplicaCount: 30
  triggers:
  - type: prometheus
    metadata:
      serverAddress: http://prometheus.monitoring:9090
      query: |
        avg(video_processing_duration_seconds) > bool 5
      threshold: "1"
```

## Outras Possibilidades do KEDA

Importante mencionar: o KEDA suporta muito mais escalers al√©m dos que implementamos aqui! Voc√™ pode escalar baseado em:

- **Filas de mensagens:** Kafka, AWS SQS, Google Pub/Sub, Azure Service Bus
- **Bancos de dados:** PostgreSQL, MySQL, MongoDB
- **M√©tricas customizadas:** Prometheus, Datadog, New Relic
- **Webhooks customizados:** Qualquer fonte de dados que voc√™ conseguir exposar via API

Neste artigo, focaremos nos exemplos pr√°ticos que temos no reposit√≥rio (RabbitMQ e Redis), mas a l√≥gica e padr√£o se aplicam para qualquer um dos scalers suportados.

**Confira a lista completa em:** https://keda.sh/docs/2.18/scalers/

A verdadeira flexibilidade vem quando voc√™ combina m√∫ltiplos escaladores. Por exemplo, voc√™ quer que sua aplica√ß√£o escale se QUALQUER UMA dessas condi√ß√µes for verdadeira:

```yaml
triggers:
- type: rabbitmq
  metadata:
    protocol: amqp
    queueName: critical-jobs
    mode: QueueLength
    value: "10"
    host: "amqp://rabbitmq:rabbitmq@rabbitmq:5672/"
- type: redis
  metadata:
    address: redis-master.redis.svc.cluster.local:6379
    listName: backup-queue
    listLength: "20"
```

Dessa forma, seus workers escalam se a fila cr√≠tica do RabbitMQ estourar OU se a lista do Redis ultrapassar o limite. Voc√™ fica coberto em m√∫ltiplos cen√°rios.

## Dicas Pr√°ticas que Aprendi no Caminho

### 1. Use `minReplicaCount` com cuidado

Se voc√™ seta `minReplicaCount: 0`, a aplica√ß√£o pode ser completamente descalada quando n√£o h√° eventos. Isso economiza recursos, mas pode adicionar lat√™ncia quando a pr√≥xima onda de eventos chega. 

Para aplica√ß√µes cr√≠ticas, mantenha pelo menos 1 ou 2 r√©plicas:

```yaml
minReplicaCount: 2
```

Para economia de recursos, √© aceit√°vel usar 0, mas prepare-se para um cold start.

### 2. Entenda o `cooldownPeriod`

Por padr√£o, o KEDA espera 300 segundos (5 minutos) antes de desescalar. Voc√™ pode mudar isso em `cooldownPeriod`, mas tenha cuidado com "thrashing" - sua aplica√ß√£o pode subir e descer constantemente se as m√©tricas oscilarem.

```yaml
cooldownPeriod: 30
```

### 3. Ajuste o `pollingInterval`

O intervalo padr√£o √© 15 segundos. Para escalers mais sens√≠veis, reduza para 10 ou at√© 5 segundos, mas considere o overhead na fonte de dados:

```yaml
pollingInterval: 10
```

### 4. Monitore o KEDA

O KEDA exp√µe suas pr√≥prias m√©tricas em `:8080/metrics`. Monitore quantas vezes seus scalers falham para conectar √†s fontes de dados. Se o RabbitMQ fica indispon√≠vel, o KEDA n√£o consegue escalar corretamente.

```bash
kubectl patch svc keda-operator-metrics-apiserver -n keda \
  -p '{"spec": {"type": "NodePort"}}'
kubectl get svc -n keda keda-operator-metrics-apiserver
```

### 5. Valores de threshold precisam de ajuste

N√£o existe valor m√°gico. Comece conservador, observe o comportamento da sua aplica√ß√£o por uma semana e ajuste. 

Se seus workers RabbitMQ processam 50 mensagens por minuto em m√©dia, um threshold de 5 mensagens por pod faz sentido. Mas isso √© espec√≠fico do seu caso:

- **RabbitMQ:** 5-20 mensagens por pod (teste primeiro!)
- **Redis:** 5-10 itens por pod
- **SQS:** 50-100 mensagens por pod

### 6. Combine com PodDisruptionBudgets

Se voc√™ vai escalar agressivamente, use PDB para evitar que o Kubernetes derrube muitos pods ao mesmo tempo durante updates:

```yaml
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: consumer-pdb
spec:
  minAvailable: 1
  selector:
    matchLabels:
      app: rabbit-consumer
```

### 7. Sempre defina Requests e Limits

Recursos inadequados fazem o scheduler ficar confuso:

```yaml
resources:
  requests:
    cpu: 100m
    memory: 128Mi
  limits:
    cpu: 500m
    memory: 512Mi
```

## Resolvendo Problemas Comuns

### Scaler n√£o est√° disparando

Verifique os logs do KEDA:

```bash
kubectl logs -n keda deployment/keda-operator
kubectl logs -n keda deployment/keda-operator-metrics-apiserver
```

Verifique o status do ScaledObject:

```bash
kubectl describe scaledobject rabbit-consumer-scaler
```

Geralmente √© problema de permiss√£o ou conex√£o √† fonte de dados.

### Escalando muito lentamente

Reduza o `pollingInterval` no trigger (padr√£o √© 15s):

```yaml
pollingInterval: 5
```

Mas n√£o coloque muito baixo ou voc√™ sobrecarrega o RabbitMQ/Redis/Prometheus.

### Pods criados, mas aplica√ß√£o n√£o processa

Geralmente √© porque a aplica√ß√£o n√£o consegue se conectar √† fila. Verifique as credenciais e a conectividade de rede:

```bash
kubectl exec -it deployment/rabbit-consumer -- sh
# Dentro do pod, testar conex√£o com RabbitMQ
```

Verifique tamb√©m os logs da aplica√ß√£o:

```bash
kubectl logs deployment/rabbit-consumer --tail=50
```

### Problemas com autentica√ß√£o no RabbitMQ

Se a senha est√° errada na configura√ß√£o do KEDA, o scaler simplesmente n√£o vai conectar. Verifique que est√° usando o mesmo usu√°rio e senha definidos no cluster:

```yaml
host: "amqp://rabbitmq:rabbitmq@NODE_IP:32662/"
```

## Conclus√£o

KEDA transformou a forma como eu penso em autoscaling. N√£o √© mais sobre "quanto calor tem?", √© sobre "quanto trabalho h√° para fazer?".

## Os Ganhos Reais em Produ√ß√£o

A curva de aprendizado √© r√°pida, mas os ganhos em efici√™ncia s√£o reais e mensur√°veis:

- ‚úÖ **Menos overprovisioning** - Voc√™ n√£o mant√©m 10 pods esperando picos que n√£o v√™m
- ‚úÖ **Melhor uso de recursos** - Escala apenas quando necess√°rio, economizando CPU, mem√≥ria e storage
- ‚úÖ **Melhor resposta a picos de tr√°fego** - Reage em tempo real ao volume real de trabalho, n√£o a m√©tricas gen√©ricas
- ‚úÖ **Economia na conta de cloud** - Redu√ß√£o significativa em custos de infraestrutura (j√° vi redu√ß√£o de 40-60% em alguns casos)

## Por Que Isso Economiza Tanto?

Imagine um cen√°rio real:

**Sem KEDA (usando s√≥ HPA com CPU):**
- 10 pods rodando o tempo todo (mesmo sem trabalho)
- Cold start de 30s quando chega pico
- Overprovisioning para cobrir imprevistos
- Custo: ~$500/m√™s em 10 pods

**Com KEDA (escalando por fila):**
- 1-2 pods em repouso
- Sobe para 10 em segundos quando fila explode
- Desce automaticamente quando fila esvazia
- Custo: ~$100-150/m√™s
- **Economia: ~70%**

Se voc√™ ainda est√° usando s√≥ CPU e mem√≥ria para escalar, eu fortemente recomendo experimentar KEDA. Seu cluster (e sua conta de cloud) v√£o agradecer.

**Todos os scalers dispon√≠veis voc√™ encontra aqui:** https://keda.sh/docs/2.18/scalers/

**C√≥digo de todos os meus artigos** (incluindo este) est√° dispon√≠vel em: https://github.com/robertasolimandonofreo/medium-projects

J√° usou KEDA em produ√ß√£o? Qual foi sua experi√™ncia? Deixa um coment√°rio a√≠! üöÄ